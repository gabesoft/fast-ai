{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/gabe/work/fast-ai/nbs'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "  .end_space {\n",
       "      min-height: 1000px;\n",
       "  }\n",
       "  .container {\n",
       "      width: 100%;\n",
       "  }\n",
       "</style"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "  .end_space {\n",
    "      min-height: 1000px;\n",
    "  }\n",
    "  .container {\n",
    "      width: 100%;\n",
    "  }\n",
    "</style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from importlib import reload\n",
    "\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '../data/statefarm'\n",
    "SAMPLE_DIR = os.path.join(DATA_DIR, 'sample')\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import utils.statefarm\n",
    "reload(utils.statefarm)\n",
    "\n",
    "import utils.trainhelper\n",
    "reload(utils.trainhelper)\n",
    "\n",
    "from utils.statefarm import *\n",
    "from utils.trainhelper import get_batches, save_model, read_model, get_classes\n",
    "from utils.utils import save_array, load_array\n",
    "\n",
    "from models.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21601 images belonging to 10 classes.\n",
      "Found 823 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n",
      "['c0/img_82409.jpg', 'c0/img_95245.jpg', 'c0/img_88538.jpg', 'c0/img_14492.jpg', 'c0/img_81194.jpg'] filenames\n",
      "10 classes\n",
      "(224, 224, 3) image shape\n"
     ]
    }
   ],
   "source": [
    "data_dir = DATA_DIR\n",
    "\n",
    "width_igen = image.ImageDataGenerator(width_shift_range=0.1)\n",
    "height_igen = image.ImageDataGenerator(height_shift_range=0.05)\n",
    "shear_igen = image.ImageDataGenerator(shear_range=0.1)\n",
    "rotation_igen = image.ImageDataGenerator(rotation_range=15)\n",
    "channel_igen = image.ImageDataGenerator(channel_shift_range=20)\n",
    "igen = image.ImageDataGenerator(rotation_range=15, \n",
    "                                height_shift_range=0.05, \n",
    "                                shear_range=0.1, \n",
    "                                channel_shift_range=20, \n",
    "                                width_shift_range=0.1)\n",
    "\n",
    "train_batches = get_batches(os.path.join(data_dir, 'train'), batch_size=BATCH_SIZE, shuffle=False)\n",
    "valid_batches = get_batches(os.path.join(data_dir, 'valid'), batch_size=BATCH_SIZE * 2, shuffle=False)\n",
    "test_batches = get_batches(os.path.join(data_dir, 'test'), batch_size=BATCH_SIZE, shuffle=False, class_mode=None)\n",
    "\n",
    "train_steps = int(np.ceil(train_batches.samples / BATCH_SIZE))\n",
    "valid_steps = int(np.ceil(valid_batches.samples / (BATCH_SIZE * 2)))\n",
    "test_steps = int(np.ceil(test_batches.samples / BATCH_SIZE))\n",
    "\n",
    "print(train_batches.filenames[:5], 'filenames')\n",
    "print(train_batches.num_class, 'classes')\n",
    "print(train_batches.image_shape, 'image shape')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the convolutional layers of VGG16 to generate outputs to the next model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top=False, pooling=None, input_shape=(224,224,3))\n",
    "\n",
    "train_vgg_preds = vgg.predict_generator(train_batches, train_steps)\n",
    "valid_vgg_preds = vgg.predict_generator(valid_batches, valid_steps)\n",
    "test_vgg_preds = vgg.predict_generator(test_batches, test_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21601, 7, 7, 512) train_vgg_preds.shape\n",
      "(823, 7, 7, 512) valid_vgg_preds.shape\n",
      "(79726, 7, 7, 512) test_vgg_preds.shape\n",
      "(7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "print(train_vgg_preds.shape, 'train_vgg_preds.shape')\n",
    "print(valid_vgg_preds.shape, 'valid_vgg_preds.shape')\n",
    "print(test_vgg_preds.shape, 'test_vgg_preds.shape')\n",
    "print(vgg.layers[-1].output_shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CACHE_DIR = os.path.join(data_dir, 'cache')\n",
    "\n",
    "save_array(os.path.join(CACHE_DIR, 'train_vgg_preds.dat'), train_vgg_preds)\n",
    "save_array(os.path.join(CACHE_DIR, 'valid_vgg_preds.dat'), valid_vgg_preds)\n",
    "save_array(os.path.join(CACHE_DIR, 'test_vgg_preds.dat'), test_vgg_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21601 images belonging to 10 classes.\n",
      "Found 823 images belonging to 10 classes.\n",
      "Found 79726 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "   train_classes,\n",
    "   valid_classes,\n",
    "   train_labels,\n",
    "   valid_labels,\n",
    "   train_filenames,\n",
    "   valid_filenames,\n",
    "   test_filenames\n",
    ") = get_classes(data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21601\n",
      "823\n",
      "21601\n",
      "823\n"
     ]
    }
   ],
   "source": [
    "print(len(train_classes))\n",
    "print(len(valid_classes))\n",
    "print(len(train_labels))\n",
    "print(len(valid_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup model and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21601 samples, validate on 823 samples\n",
      "Epoch 1/10\n",
      "21601/21601 [==============================] - 7s - loss: 6.5389 - acc: 0.0998 - val_loss: 2.2983 - val_acc: 0.0595\n",
      "Epoch 2/10\n",
      "21601/21601 [==============================] - 6s - loss: 5.8983 - acc: 0.1092 - val_loss: 2.1577 - val_acc: 0.2139\n",
      "Epoch 3/10\n",
      "21601/21601 [==============================] - 6s - loss: 5.3204 - acc: 0.1226 - val_loss: 2.0730 - val_acc: 0.2734\n",
      "Epoch 4/10\n",
      "21601/21601 [==============================] - 6s - loss: 4.8276 - acc: 0.1268 - val_loss: 1.9901 - val_acc: 0.3609\n",
      "Epoch 5/10\n",
      "21601/21601 [==============================] - 6s - loss: 4.3340 - acc: 0.1401 - val_loss: 1.9271 - val_acc: 0.4083\n",
      "Epoch 6/10\n",
      "21601/21601 [==============================] - 6s - loss: 3.9083 - acc: 0.1502 - val_loss: 1.8739 - val_acc: 0.4070\n",
      "Epoch 7/10\n",
      "21601/21601 [==============================] - 6s - loss: 3.5191 - acc: 0.1634 - val_loss: 1.8190 - val_acc: 0.3998\n",
      "Epoch 8/10\n",
      "21601/21601 [==============================] - 6s - loss: 3.1746 - acc: 0.1810 - val_loss: 1.7619 - val_acc: 0.4800\n",
      "Epoch 9/10\n",
      "21601/21601 [==============================] - 6s - loss: 2.8508 - acc: 0.2012 - val_loss: 1.7134 - val_acc: 0.5200\n",
      "Epoch 10/10\n",
      "21601/21601 [==============================] - 6s - loss: 2.5710 - acc: 0.2248 - val_loss: 1.6600 - val_acc: 0.5249\n",
      "Train on 21601 samples, validate on 823 samples\n",
      "Epoch 1/10\n",
      "21601/21601 [==============================] - 6s - loss: 2.3672 - acc: 0.2440 - val_loss: 1.6104 - val_acc: 0.5371\n",
      "Epoch 2/10\n",
      "21601/21601 [==============================] - 6s - loss: 2.1789 - acc: 0.2740 - val_loss: 1.5605 - val_acc: 0.5917\n",
      "Epoch 3/10\n",
      "21601/21601 [==============================] - 6s - loss: 2.0220 - acc: 0.3008 - val_loss: 1.5121 - val_acc: 0.5869\n",
      "Epoch 4/10\n",
      "21601/21601 [==============================] - 6s - loss: 1.8688 - acc: 0.3323 - val_loss: 1.4622 - val_acc: 0.5747\n",
      "Epoch 5/10\n",
      "21601/21601 [==============================] - 6s - loss: 1.7701 - acc: 0.3619 - val_loss: 1.4119 - val_acc: 0.6148\n",
      "Epoch 6/10\n",
      "21601/21601 [==============================] - 6s - loss: 1.6552 - acc: 0.4010 - val_loss: 1.3608 - val_acc: 0.6185\n",
      "Epoch 7/10\n",
      "21601/21601 [==============================] - 6s - loss: 1.5634 - acc: 0.4310 - val_loss: 1.3063 - val_acc: 0.6440\n",
      "Epoch 8/10\n",
      "21601/21601 [==============================] - 6s - loss: 1.4654 - acc: 0.4629 - val_loss: 1.2595 - val_acc: 0.6391\n",
      "Epoch 9/10\n",
      "21601/21601 [==============================] - 6s - loss: 1.3994 - acc: 0.4869 - val_loss: 1.2109 - val_acc: 0.6513\n",
      "Epoch 10/10\n",
      "21601/21601 [==============================] - 6s - loss: 1.3120 - acc: 0.5190 - val_loss: 1.1620 - val_acc: 0.6707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f664c860128>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DROPOUT_RATE = 0.9\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=vgg.layers[-1].output_shape[1:]),\n",
    "    Dropout(DROPOUT_RATE),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(DROPOUT_RATE),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(DROPOUT_RATE),\n",
    "    \n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_vgg_preds, train_labels, batch_size=BATCH_SIZE, epochs=10, validation_data=(valid_vgg_preds, valid_labels))\n",
    "\n",
    "model.optimizer.lr = 0.001\n",
    "model.fit(train_vgg_preds, train_labels, batch_size=BATCH_SIZE, epochs=10, validation_data=(valid_vgg_preds, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21601 samples, validate on 823 samples\n",
      "Epoch 1/10\n",
      "21601/21601 [==============================] - 6s - loss: 1.2385 - acc: 0.5534 - val_loss: 1.1154 - val_acc: 0.6768\n",
      "Epoch 2/10\n",
      "21601/21601 [==============================] - 6s - loss: 1.1772 - acc: 0.5748 - val_loss: 1.0355 - val_acc: 0.7375\n",
      "Epoch 3/10\n",
      "21601/21601 [==============================] - 6s - loss: 1.1049 - acc: 0.6008 - val_loss: 0.9859 - val_acc: 0.7643\n",
      "Epoch 4/10\n",
      "21601/21601 [==============================] - 6s - loss: 1.0465 - acc: 0.6250 - val_loss: 0.9621 - val_acc: 0.7558\n",
      "Epoch 5/10\n",
      "21601/21601 [==============================] - 6s - loss: 0.9901 - acc: 0.6463 - val_loss: 0.9137 - val_acc: 0.7643\n",
      "Epoch 6/10\n",
      "21601/21601 [==============================] - 6s - loss: 0.9423 - acc: 0.6632 - val_loss: 0.9080 - val_acc: 0.7546\n",
      "Epoch 7/10\n",
      "21601/21601 [==============================] - 6s - loss: 0.8899 - acc: 0.6917 - val_loss: 0.8768 - val_acc: 0.7533\n",
      "Epoch 8/10\n",
      "21601/21601 [==============================] - 6s - loss: 0.8387 - acc: 0.7094 - val_loss: 0.8699 - val_acc: 0.7375\n",
      "Epoch 9/10\n",
      "21601/21601 [==============================] - 6s - loss: 0.7974 - acc: 0.7248 - val_loss: 0.8564 - val_acc: 0.7448\n",
      "Epoch 10/10\n",
      "21601/21601 [==============================] - 6s - loss: 0.7700 - acc: 0.7361 - val_loss: 0.8523 - val_acc: 0.7327\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f66fb49be80>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-3\n",
    "model.fit(train_vgg_preds, train_labels, batch_size=BATCH_SIZE, epochs=10, validation_data=(valid_vgg_preds, valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 256)               6422784   \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 6,493,194\n",
      "Trainable params: 6,492,170\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_model(data_dir, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = model.predict(test_vgg_preds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 79726 images belonging to 1 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected flatten_22_input to have shape (None, 7, 7, 512) but got array with shape (64, 224, 224, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-e579727d0ff5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   1192\u001b[0m                                             \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m                                             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m                                             verbose=verbose)\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2288\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2290\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2291\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict_on_batch\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1817\u001b[0m         \"\"\"\n\u001b[1;32m   1818\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m-> 1819\u001b[0;31m                                     self._feed_input_shapes)\n\u001b[0m\u001b[1;32m   1820\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1821\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    142\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    145\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected flatten_22_input to have shape (None, 7, 7, 512) but got array with shape (64, 224, 224, 3)"
     ]
    }
   ],
   "source": [
    "test_dir = os.path.join(data_dir, 'test')\n",
    "test_batches = get_batches(test_dir, shuffle=False, batch_size=BATCH_SIZE, class_mode=None)\n",
    "test_steps = int(np.ceil(test_batches.samples / BATCH_SIZE))\n",
    "test_preds = model.predict_generator(test_batches, test_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_preds = model.predict(valid_vgg_preds, batch_size=BATCH_SIZE*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 823 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_dir = os.path.join(data_dir, 'valid')\n",
    "valid_batches = get_batches(valid_dir, batch_size=BATCH_SIZE * 2, shuffle=False)\n",
    "valid_steps = int(np.ceil(valid_batches.samples / (BATCH_SIZE * 2)))\n",
    "valid_preds = model.predict_generator(valid_batches, valid_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "results_dir = os.path.join(data_dir, 'results')\n",
    "save_array(os.path.join(results_dir, 'predictions'), test_preds)\n",
    "save_array(os.path.join(results_dir, 'filenames'), test_batches.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.metrics import log_loss\n",
    "from keras import backend as K\n",
    "\n",
    "def onehot(x):\n",
    "    to_categorical(x, 10)\n",
    "    \n",
    "def do_clip(arr, mx):\n",
    "    return np.clip(arr, (1 - mx) / 9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  0.  0. ...,  0.  0.  1.]] valid_labels\n",
      "float32 valid_labels type\n",
      "(823, 10) valid_labels.shape\n",
      "[[ 0.32545128  0.00920499  0.00777778 ...,  0.00777778  0.00777778\n",
      "   0.61253059]\n",
      " [ 0.67435294  0.00777778  0.00777778 ...,  0.00777778  0.00777778\n",
      "   0.28782073]\n",
      " [ 0.62463993  0.00777778  0.00777778 ...,  0.00777778  0.00777778\n",
      "   0.28785765]\n",
      " ..., \n",
      " [ 0.08136775  0.02805007  0.02607597 ...,  0.03632662  0.30010533\n",
      "   0.50303668]\n",
      " [ 0.33036822  0.03377842  0.01220943 ...,  0.00777778  0.07727412\n",
      "   0.47432873]\n",
      " [ 0.23242027  0.0451872   0.03887215 ...,  0.01095971  0.26165023\n",
      "   0.29060861]] valid_preds_c type\n",
      "float32 valid_preds_c\n",
      "(823, 10) valid_preds_c.shape\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-64e1e0e03329>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mvalid_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_preds_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   1638\u001b[0m     \u001b[0mThe\u001b[0m \u001b[0mlogarithm\u001b[0m \u001b[0mused\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnatural\u001b[0m \u001b[0mlogarithm\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m     \"\"\"\n\u001b[0;32m-> 1640\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1641\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;31m# make sure we actually converted to numeric:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"O\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "valid_classes = valid_batches.classes\n",
    "valid_labels = to_categorical(valid_classes, 10).astype('float32')\n",
    "\n",
    "valid_preds_c = do_clip(valid_preds, 0.93)\n",
    "\n",
    "print(valid_labels, 'valid_labels')\n",
    "print(valid_labels.dtype, 'valid_labels type')\n",
    "print(valid_labels.shape, 'valid_labels.shape')\n",
    "\n",
    "print(valid_preds_c, 'valid_preds_c type')\n",
    "print(valid_preds_c.dtype, 'valid_preds_c')\n",
    "print(valid_preds_c.shape, 'valid_preds_c.shape')\n",
    "\n",
    "cc = categorical_crossentropy(K.constant(valid_labels), K.constant(valid_preds_c))\n",
    "valid_mean = np.mean(cc.eval(session=K.get_session()))\n",
    "\n",
    "score = log_loss(valid_labels, valid_preds_c))\n",
    "\n",
    "print(valid_mean, 'validation mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04818407,  0.00777778,  0.01461318, ...,  0.00777778,\n",
       "         0.0098451 ,  0.00777778],\n",
       "       [ 0.89036   ,  0.00779618,  0.00777778, ...,  0.00777778,\n",
       "         0.00777778,  0.06173703],\n",
       "       [ 0.00777778,  0.0145776 ,  0.91266948, ...,  0.00777778,\n",
       "         0.02415638,  0.00777778],\n",
       "       ..., \n",
       "       [ 0.43349975,  0.3404859 ,  0.04322587, ...,  0.00777778,\n",
       "         0.02240543,  0.0698687 ],\n",
       "       [ 0.00777778,  0.01101675,  0.11367005, ...,  0.70606726,\n",
       "         0.11160305,  0.00823002],\n",
       "       [ 0.26121113,  0.05492519,  0.05338839, ...,  0.02645271,\n",
       "         0.10260747,  0.22411396]], dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_c = do_clip(test_preds, 0.93)\n",
    "test_preds_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read model from cache and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "338/338 [==============================] - 183s - loss: 1.5169 - acc: 0.5037 - val_loss: 5.3738 - val_acc: 0.2224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbdcd7ace80>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1 = read_model(data_dir, 'architecture-2017-10-10-22.json', 'model-weights-2017-10-10-22.json')\n",
    "\n",
    "m1.compile(Adam(lr=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "m1.optimizer.lr = 0.008\n",
    "m1.fit_generator(t_batches, t_steps, epochs=1, validation_data=v_batches, validation_steps=v_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_31 (Batc (None, 224, 224, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 222, 222, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 222, 222, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 72, 72, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 72, 72, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 36864)             0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 200)               7373000   \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                2010      \n",
      "=================================================================\n",
      "Total params: 7,395,598\n",
      "Trainable params: 7,395,000\n",
      "Non-trainable params: 598\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
